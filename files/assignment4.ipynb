{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cde191",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9c85502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Welcome to Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         headers\n",
       "0           Welcome to Wikipedia\n",
       "1  From today's featured article\n",
       "2               Did you know ...\n",
       "3                    In the news\n",
       "4                    On this day\n",
       "5       Today's featured picture\n",
       "6       Other areas of Wikipedia\n",
       "7    Wikipedia's sister projects\n",
       "8            Wikipedia languages"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1# Write a python program to display all the header tags from wikipedia.org and make data frame.\n",
    "page = requests.get('https://en.wikipedia.org/wiki/Main_Page' )\n",
    "page\n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "headings = []\n",
    "for heading in soup.find_all('span', class_='mw-headline'):\n",
    "    headings.append(heading.text)\n",
    "headings\n",
    "\n",
    "df = pd.DataFrame({ 'headers' : headings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a6eca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>president_names</th>\n",
       "      <th>terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shri Ram Nath Kovind</td>\n",
       "      <td>14th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shri Pranab Mukherjee</td>\n",
       "      <td>13th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Smt Pratibha Devisingh Patil</td>\n",
       "      <td>12th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DR. A.P.J. Abdul Kalam</td>\n",
       "      <td>11th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shri K. R. Narayanan</td>\n",
       "      <td>10th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dr Shankar Dayal Sharma</td>\n",
       "      <td>9th  President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shri R Venkataraman</td>\n",
       "      <td>8th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Giani Zail Singh</td>\n",
       "      <td>7th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shri Neelam Sanjiva Reddy</td>\n",
       "      <td>6th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dr. Fakhruddin Ali Ahmed</td>\n",
       "      <td>5th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shri Varahagiri Venkata Giri</td>\n",
       "      <td>4th President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dr. Zakir Husain</td>\n",
       "      <td>3rd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Dr. Sarvepalli Radhakrishnan</td>\n",
       "      <td>2nd President of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dr. Rajendra Prasad</td>\n",
       "      <td>1st President of India</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 president_names                    terms\n",
       "0           Shri Ram Nath Kovind  14th President of India\n",
       "1          Shri Pranab Mukherjee  13th President of India\n",
       "2   Smt Pratibha Devisingh Patil  12th President of India\n",
       "3         DR. A.P.J. Abdul Kalam  11th President of India\n",
       "4           Shri K. R. Narayanan  10th President of India\n",
       "5        Dr Shankar Dayal Sharma  9th  President of India\n",
       "6            Shri R Venkataraman   8th President of India\n",
       "7               Giani Zail Singh   7th President of India\n",
       "8      Shri Neelam Sanjiva Reddy   6th President of India\n",
       "9       Dr. Fakhruddin Ali Ahmed   5th President of India\n",
       "10  Shri Varahagiri Venkata Giri   4th President of India\n",
       "11              Dr. Zakir Husain   3rd President of India\n",
       "12  Dr. Sarvepalli Radhakrishnan   2nd President of India\n",
       "13           Dr. Rajendra Prasad   1st President of India"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #2 ) Write s python program to display list of respected former presidents of India(i.e. Name , Term ofoffice)\n",
    "page1 = requests.get('https://presidentofindia.nic.in/former-presidents')\n",
    "soup = BeautifulSoup(page1.content)\n",
    "\n",
    "president_names = []\n",
    "\n",
    "names = soup.find_all('div', class_='president-listing')\n",
    "\n",
    "for president in names:\n",
    "    h3_element = president.find('h3')\n",
    "    name = h3_element.text.strip()\n",
    "    president_names.append(name)\n",
    "\n",
    "president_names\n",
    "\n",
    "terms = []\n",
    "for president in names:\n",
    "    h5_element = president.find('h5')\n",
    "    name1 = h5_element.text.strip()\n",
    "    terms.append(name1)\n",
    "terms\n",
    "\n",
    "list_presidents = pd.DataFrame({'president_names' :president_names, 'terms' :terms })\n",
    "list_presidents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93ca3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------***********----------------------------------\n",
      "Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
      "----------------------***********----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teams</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>55</td>\n",
       "      <td>6,640</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>42</td>\n",
       "      <td>4,926</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>34</td>\n",
       "      <td>3,750</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>36</td>\n",
       "      <td>3,922</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>43</td>\n",
       "      <td>4,399</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>England</td>\n",
       "      <td>38</td>\n",
       "      <td>3,777</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>47</td>\n",
       "      <td>4,134</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>44</td>\n",
       "      <td>3,836</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>2,533</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teams matches points rating\n",
       "0         India      55  6,640    121\n",
       "1     Australia      42  4,926    117\n",
       "2  South Africa      34  3,750    110\n",
       "3      Pakistan      36  3,922    109\n",
       "4   New Zealand      43  4,399    102\n",
       "5       England      38  3,777     99\n",
       "6     Sri Lanka      47  4,134     88\n",
       "7    Bangladesh      44  3,836     87\n",
       "8   Afghanistan      30  2,533     84\n",
       "9   West Indies      38  2,582     68"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3 ) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame \n",
    "  #a) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "print('----------------------***********----------------------------------')\n",
    "print('Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.' )\n",
    "print('----------------------***********----------------------------------')\n",
    "page2 = requests.get('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "page2\n",
    "\n",
    "soup2 = BeautifulSoup(page2.content)\n",
    "soup2\n",
    "\n",
    "teams = []\n",
    "top = 0\n",
    "for i in soup2.find_all('span' , class_ = \"u-hide-phablet\"):\n",
    "    if top < 10:\n",
    "        teams.append(i.text)\n",
    "        top += 1\n",
    "teams\n",
    "\n",
    "rating = []\n",
    "top1 = 0\n",
    "for i in soup2.find_all('td' , class_ = \"table-body__cell u-text-right rating\"):\n",
    "    if top1 < 9:\n",
    "        rating.append(i.text)\n",
    "        top1 += 1\n",
    "first = soup2.find('td' , class_ =\"rankings-block__banner--rating u-text-right\")\n",
    "rating.insert(0, first.text.strip())\n",
    "rating\n",
    "\n",
    "points_rate = []\n",
    "top02 = 0\n",
    "for i in soup2.find_all('td' , class_ = \"table-body__cell u-center-text\"):\n",
    "    if top02 < 18:\n",
    "        points_rate.append(i.text)\n",
    "        top02 += 1\n",
    "        \n",
    "matches = points_rate[::2][:10]\n",
    "points = points_rate[1::2][:10]\n",
    "\n",
    "first1 = soup2.find('td' , class_ = \"rankings-block__banner--points\")\n",
    "points.insert(0, first1.text.strip())\n",
    "\n",
    "first2 = soup2.find('td' , class_ = \"rankings-block__banner--matches\")\n",
    "matches.insert(0, first2.text)\n",
    "\n",
    "data01 = pd.DataFrame({'teams' : teams, 'matches' : matches, 'points' : points, 'rating' : rating})\n",
    "data01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8617a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------***********----------------------------------\n",
      "Top 10 ODI batsmen along with the records of their team and rating.\n",
      "----------------------***********----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shubman Gill</td>\n",
       "      <td>IND</td>\n",
       "      <td>826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daryl Mitchell</td>\n",
       "      <td>NZ</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rassie van der Dussen</td>\n",
       "      <td>SA</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Harry Tector</td>\n",
       "      <td>IRE</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dawid Malan</td>\n",
       "      <td>ENG</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  player team rating\n",
       "0           Shubman Gill  IND    826\n",
       "1             Babar Azam  PAK    824\n",
       "2            Virat Kohli  IND    791\n",
       "3           Rohit Sharma  IND    769\n",
       "4        Quinton de Kock   SA    760\n",
       "5         Daryl Mitchell   NZ    750\n",
       "6           David Warner  AUS    745\n",
       "7  Rassie van der Dussen   SA    735\n",
       "8           Harry Tector  IRE    729\n",
       "9            Dawid Malan  ENG    729"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b) Top 10 ODI Batsmen along with the records of their team andrating.\n",
    "print('----------------------***********----------------------------------')\n",
    "print('Top 10 ODI batsmen along with the records of their team and rating.' )\n",
    "print('----------------------***********----------------------------------')\n",
    "page5 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page5\n",
    "\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "soup5\n",
    "\n",
    "player = []\n",
    "top05 = 0\n",
    "for i in soup5.find('div' , class_ = \"rankings-block__banner--name\"):\n",
    "    if top05 < 10:\n",
    "        player.append(i.text)\n",
    "        top05 += 1\n",
    "player\n",
    "\n",
    "top06 = 0\n",
    "for i in soup5.find_all('td' , class_ = \"table-body__cell name\"):\n",
    "    if top06 < 9:\n",
    "        player.append(i.text.strip())\n",
    "        top06 += 1\n",
    "player\n",
    "\n",
    "team01 = soup5.find('div', class_='rankings-block__banner--nationality')\n",
    "team0001 = team01.select_one('.flag-15')['class'][1]\n",
    "team0001\n",
    "\n",
    "top06 = 0\n",
    "team001 = []\n",
    "for i in soup5.find_all('span' , class_ = \"table-body__logo-text\"):\n",
    "    if top06 < 9:\n",
    "        team001.append(i.text.strip())\n",
    "        top06 += 1\n",
    "team001.insert(0, team0001 )\n",
    "team001\n",
    "\n",
    "rating = []\n",
    "rate = soup5.find('div', class_='rankings-block__banner--rating')\n",
    "rate001 = rating.insert(0, rate.text)\n",
    "\n",
    "top07 = 0\n",
    "for i in soup5.find_all('td' , class_ = \"table-body__cell u-text-right rating\"):\n",
    "    if top07 < 9:\n",
    "        rating.append(i.text.strip())\n",
    "        top07 += 1\n",
    "rating\n",
    "\n",
    "data03 = pd.DataFrame({'player' : player, 'team' : team001, 'rating' : rating})\n",
    "data03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff57d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------***********----------------------------------\n",
      "Top 10 ODI bowlers along with the records of their team and rating.\n",
      "----------------------***********----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keshav Maharaj</td>\n",
       "      <td>SA</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mohammed Siraj</td>\n",
       "      <td>IND</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adam Zampa</td>\n",
       "      <td>AUS</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rashid Khan</td>\n",
       "      <td>AFG</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kuldeep Yadav</td>\n",
       "      <td>IND</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shaheen Afridi</td>\n",
       "      <td>PAK</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammad Shami</td>\n",
       "      <td>IND</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           player team rating\n",
       "0  Keshav Maharaj   SA    741\n",
       "1  Josh Hazlewood  AUS    703\n",
       "2  Mohammed Siraj  IND    699\n",
       "3  Jasprit Bumrah  IND    685\n",
       "4      Adam Zampa  AUS    675\n",
       "5     Rashid Khan  AFG    667\n",
       "6   Kuldeep Yadav  IND    667\n",
       "7     Trent Boult   NZ    663\n",
       "8  Shaheen Afridi  PAK    650\n",
       "9  Mohammad Shami  IND    648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "print('----------------------***********----------------------------------')\n",
    "print('Top 10 ODI bowlers along with the records of their team and rating.' )\n",
    "print('----------------------***********----------------------------------')\n",
    "\n",
    "page6 = requests.get('https://www.icc-cricket.com/rankings/mens/player-rankings/odi')\n",
    "page6\n",
    "\n",
    "soup6 = BeautifulSoup(page6.content)\n",
    "soup6\n",
    "\n",
    "bowler= []\n",
    "player01 = []\n",
    "player0002 = []\n",
    "top05 = 0\n",
    "for i in soup6.find_all('div' , class_ = \"rankings-block__banner--name\"):\n",
    "    if top05 < 10:\n",
    "        player0002.append(i.text)\n",
    "        top05 += 1\n",
    "bowler.append(player0002[1])\n",
    "bowler\n",
    "top11 = 0\n",
    "for i in soup6.find_all('td' , class_ = \"table-body__cell name\"):\n",
    "        player01.append(i.text.strip())\n",
    "        top11 += 1\n",
    "bowler1 = bowler + player01[9:18]\n",
    "bowler1\n",
    "\n",
    "team0003 = []\n",
    "team0002 = soup6.find_all('div', class_='rankings-block__banner--nationality')\n",
    "team0002\n",
    "flag = []\n",
    "for team_div in team0002:\n",
    "    flag_class = team_div.find('div', class_='flag-15')['class'][1]\n",
    "    rating = team_div.find('div', class_='rankings-block__banner--rating').text.strip()\n",
    "    flag.append(flag_class)\n",
    "team0003.insert(0, flag[1])\n",
    "\n",
    "team001 = []\n",
    "for i in soup6.find_all('span' , class_ = \"table-body__logo-text\"):\n",
    "    team001.append(i.text.strip())\n",
    "team001\n",
    "bowl_team = team0003+team001[9:18]\n",
    "bowl_team\n",
    "\n",
    "rating01 = []\n",
    "rating001 = []\n",
    "for i in soup6.find_all('div', class_='rankings-block__banner--rating'):\n",
    "    rating001.append(i.text)\n",
    "rating01.insert(0, rating001[1])\n",
    "rating01\n",
    "\n",
    "rating0004 = []\n",
    "for i in soup6.find_all('td' , class_ = \"table-body__cell u-text-right rating\"):\n",
    "    rating0004.append(i.text)\n",
    "bowl_rate =rating01 +rating0004[9:18]\n",
    "bowl_rate\n",
    "\n",
    "data04 = pd.DataFrame({'player' : bowler1, 'team' : bowl_team, 'rating' : bowl_rate})\n",
    "data04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "932576a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------***********----------------------------------\n",
      "Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
      "----------------------***********----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teams</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>55</td>\n",
       "      <td>6,640</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>42</td>\n",
       "      <td>4,926</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>34</td>\n",
       "      <td>3,750</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>36</td>\n",
       "      <td>3,922</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>43</td>\n",
       "      <td>4,399</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>England</td>\n",
       "      <td>38</td>\n",
       "      <td>3,777</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>47</td>\n",
       "      <td>4,134</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>44</td>\n",
       "      <td>3,836</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>30</td>\n",
       "      <td>2,533</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>38</td>\n",
       "      <td>2,582</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teams matches points rating\n",
       "0         India      55  6,640    121\n",
       "1     Australia      42  4,926    117\n",
       "2  South Africa      34  3,750    110\n",
       "3      Pakistan      36  3,922    109\n",
       "4   New Zealand      43  4,399    102\n",
       "5       England      38  3,777     99\n",
       "6     Sri Lanka      47  4,134     88\n",
       "7    Bangladesh      44  3,836     87\n",
       "8   Afghanistan      30  2,533     84\n",
       "9   West Indies      38  2,582     68"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4) Write a python program to scrape cricket rankings from icc-cricket.com. You have to scrape and make data frame\n",
    "#a) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "print('----------------------***********----------------------------------')\n",
    "print('Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.' )\n",
    "print('----------------------***********----------------------------------')\n",
    "\n",
    "page3 = requests.get('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "page3\n",
    "\n",
    "soup3 = BeautifulSoup(page2.content)\n",
    "soup3\n",
    "\n",
    "teams1 = []\n",
    "top = 0\n",
    "for i in soup3.find_all('span' , class_ = \"u-hide-phablet\"):\n",
    "    if top < 10:\n",
    "        teams1.append(i.text)\n",
    "        top += 1\n",
    "teams1\n",
    "\n",
    "rating = []\n",
    "top4 = 0\n",
    "for i in soup3.find_all('td' , class_ = \"table-body__cell u-text-right rating\"):\n",
    "    if top4 < 9:\n",
    "        rating.append(i.text)\n",
    "        top4 += 1\n",
    "first = soup3.find('td' , class_ =\"rankings-block__banner--rating u-text-right\")\n",
    "rating.insert(0, first.text.strip())\n",
    "rating\n",
    "\n",
    "points_rate = []\n",
    "top2 = 0\n",
    "for i in soup3.find_all('td' , class_ = \"table-body__cell u-center-text\"):\n",
    "    if top2 < 18:\n",
    "        points_rate.append(i.text)\n",
    "        top2 += 1\n",
    "        \n",
    "matches = points_rate[::2][:10]\n",
    "points = points_rate[1::2][:10]\n",
    "\n",
    "first1 = soup3.find('td' , class_ = \"rankings-block__banner--points\")\n",
    "points.insert(0, first1.text)\n",
    "\n",
    "first2 = soup3.find('td' , class_ = \"rankings-block__banner--matches\")\n",
    "matches.insert(0, first2.text)\n",
    "\n",
    "data02 = pd.DataFrame({'teams' : teams, 'matches' : matches, 'points' : points, 'rating' : rating})\n",
    "data02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e15493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------***********----------------------------------\n",
      " Top 10 women’s ODI Batting players along with the records of their team and rating\n",
      "----------------------***********----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chamari Athapaththu</td>\n",
       "      <td>SL</td>\n",
       "      <td>736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harmanpreet Kaur</td>\n",
       "      <td>IND</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 player team rating\n",
       "0  Natalie Sciver-Brunt  ENG    807\n",
       "1           Beth Mooney  AUS    750\n",
       "2   Chamari Athapaththu   SL    736\n",
       "3       Laura Wolvaardt   SA    727\n",
       "4       Smriti Mandhana  IND    708\n",
       "5          Alyssa Healy  AUS    698\n",
       "6          Ellyse Perry  AUS    697\n",
       "7      Harmanpreet Kaur  IND    694\n",
       "8           Meg Lanning  AUS    662\n",
       "9        Marizanne Kapp   SA    642"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b) Top 10 women’s ODI Batting players along with the records of their team and rating\n",
    "print('----------------------***********----------------------------------')\n",
    "print(' Top 10 women’s ODI Batting players along with the records of their team and rating' )\n",
    "print('----------------------***********----------------------------------')\n",
    "\n",
    "page4 = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page4\n",
    "\n",
    "soup4 = BeautifulSoup(page4.content)\n",
    "soup4\n",
    "\n",
    "player = []\n",
    "top05 = 0\n",
    "for i in soup4.find('div' , class_ = \"rankings-block__banner--name\"):\n",
    "    if top05 < 10:\n",
    "        player.append(i.text)\n",
    "        top05 += 1\n",
    "player\n",
    "\n",
    "top06 = 0\n",
    "for i in soup4.find_all('td' , class_ = \"table-body__cell name\"):\n",
    "    if top06 < 9:\n",
    "        player.append(i.text.strip())\n",
    "        top06 += 1\n",
    "player\n",
    "\n",
    "team01 = soup4.find('div', class_='rankings-block__banner--nationality')\n",
    "team0001 = team01.select_one('.flag-15')['class'][1]\n",
    "team0001\n",
    "\n",
    "top06 = 0\n",
    "team001 = []\n",
    "for i in soup4.find_all('span' , class_ = \"table-body__logo-text\"):\n",
    "    if top06 < 9:\n",
    "        team001.append(i.text.strip())\n",
    "        top06 += 1\n",
    "team001.insert(0, team0001 )\n",
    "team001\n",
    "\n",
    "rating = []\n",
    "rate = soup4.find('div', class_='rankings-block__banner--rating')\n",
    "rate001 = rating.insert(0, rate.text)\n",
    "\n",
    "top07 = 0\n",
    "for i in soup4.find_all('td' , class_ = \"table-body__cell u-text-right rating\"):\n",
    "    if top07 < 9:\n",
    "        rating.append(i.text.strip())\n",
    "        top07 += 1\n",
    "rating\n",
    "\n",
    "data02 = pd.DataFrame({'player' : player, 'team' : team001, 'rating' : rating})\n",
    "data02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0df49f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------***********----------------------------------\n",
      "list of the women’s ODI all-rounder along with the records of their team and rating\n",
      "----------------------***********----------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>team</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Natalie Sciver-Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hayley Matthews</td>\n",
       "      <td>WI</td>\n",
       "      <td>358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nida Dar</td>\n",
       "      <td>PAK</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 player team rating\n",
       "0        Marizanne Kapp   SA    385\n",
       "1      Ashleigh Gardner  AUS    377\n",
       "2  Natalie Sciver-Brunt  ENG    360\n",
       "3       Hayley Matthews   WI    358\n",
       "4           Amelia Kerr   NZ    346\n",
       "5         Deepti Sharma  IND    312\n",
       "6          Ellyse Perry  AUS    282\n",
       "7              Nida Dar  PAK    240\n",
       "8         Jess Jonassen  AUS    227\n",
       "9         Sophie Devine   NZ    227"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c) Top 10 women’s ODI all-rounder along with the records of their team and rating\n",
    "print('----------------------***********----------------------------------')\n",
    "print('list of the women’s ODI all-rounder along with the records of their team and rating' )\n",
    "print('----------------------***********----------------------------------')\n",
    "\n",
    "page5 = requests.get('https://www.icc-cricket.com/rankings/womens/player-rankings/odi')\n",
    "page5\n",
    "\n",
    "soup7 = BeautifulSoup(page5.content)\n",
    "soup7\n",
    "\n",
    "w_bowler= []\n",
    "player01 = []\n",
    "player0002 = []\n",
    "top05 = 0\n",
    "for i in soup7.find_all('div' , class_ = \"rankings-block__banner--name\"):\n",
    "    if top05 < 10:\n",
    "        player0002.append(i.text)\n",
    "        top05 += 1\n",
    "w_bowler.append(player0002[2])\n",
    "w_bowler\n",
    "top11 = 0\n",
    "for i in soup7.find_all('td' , class_ = \"table-body__cell name\"):\n",
    "        player01.append(i.text.strip())\n",
    "        top11 += 1\n",
    "bowler2 = w_bowler + player01[18:]\n",
    "bowler2\n",
    "\n",
    "team0000 = []\n",
    "team0100 = soup7.find_all('div', class_='rankings-block__banner--nationality')\n",
    "team0100\n",
    "flag = []\n",
    "for team_div in team0100:\n",
    "    flag_class = team_div.find('div', class_='flag-15')['class'][1]\n",
    "    rating = team_div.find('div', class_='rankings-block__banner--rating').text.strip()\n",
    "    flag.append(flag_class)\n",
    "team0000.insert(0, flag[2])\n",
    "\n",
    "team0110 = []\n",
    "for i in soup7.find_all('span' , class_ = \"table-body__logo-text\"):\n",
    "    team0110.append(i.text.strip())\n",
    "team0110\n",
    "w_bowl_team = team0000+team0110[18:]\n",
    "w_bowl_team\n",
    "\n",
    "rating00 = []\n",
    "rating111 = []\n",
    "for i in soup7.find_all('div', class_='rankings-block__banner--rating'):\n",
    "    rating111.append(i.text)\n",
    "rating00.insert(0, rating111[2])\n",
    "rating00\n",
    "\n",
    "rating4444 = []\n",
    "for i in soup7.find_all('td' , class_ = \"table-body__cell u-text-right rating\"):\n",
    "    rating4444.append(i.text)\n",
    "w_bowl_rate =rating00 +rating4444[18:]\n",
    "w_bowl_rate\n",
    "\n",
    "data08 = pd.DataFrame({'player' : bowler2, 'team' : w_bowl_team, 'rating' : w_bowl_rate})\n",
    "data08\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc0b5ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>News</th>\n",
       "      <th>Time</th>\n",
       "      <th>News links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Why a strong Black Friday may not mean a blowo...</td>\n",
       "      <td>27 Min Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/03/what-strong-bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMF chief makes the case for carbon pricing at...</td>\n",
       "      <td>5 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/03/imf-chief-make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Congress and in class: Rep. Don Beyer works...</td>\n",
       "      <td>17 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/in-congress-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Case for gold fever: NewEdge Wealth sees recor...</td>\n",
       "      <td>21 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/case-for-gold-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Signs of a sector rotation — plus 2 more theme...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/signs-of-a-sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Disney's 'Wish' director left med school for a...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/disneys-wish-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>We spent $4.5 million to turn this abandoned s...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/schwab-pennsyl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Worth the money: 4 items that will upgrade you...</td>\n",
       "      <td>22 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/items-to-upgra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I spent 20 years studying foods 100-year-old p...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/i-spent-20-yea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trailer park caretaker surprises his hometown ...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/trailer-park-c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Beyoncé film: Criticism motivated 11-year-old ...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/beyonce-film-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Investors mourn the loss of one-of-a-kind lege...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/charlie-munger...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How some of 2023's biggest AI winners have far...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/how-these-ai-w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Analysts top picks for December's include this...</td>\n",
       "      <td>23 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/decembers-best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Here’s what the S&amp;P 500’s summer hot streak ca...</td>\n",
       "      <td>24 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/heres-what-the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>How $100 billion mining giant Rio Tinto is poi...</td>\n",
       "      <td>24 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/how-rio-tinto-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Social Security benefits are reduced for publi...</td>\n",
       "      <td>24 Hours Ago</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/social-securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Pfizer's twice-daily weight loss pill joins a ...</td>\n",
       "      <td>December 2, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/pfizer-weight-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Exxon Mobil CEO urges COP28 climate summit to ...</td>\n",
       "      <td>December 2, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/02/exxon-mobil-ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cramer's optimistic on retail stocks and consu...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/cramers-optimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Cramer's Lightning Round: ImmunityBio is 'a ve...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/cramers-lightn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Cramer's week ahead: Pay attention to Friday's...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/cramers-week-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Amazon broke federal labor law in calling Stat...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/amazon-broke-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Uber shares pop on inclusion in S&amp;P 500</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/uber-shares-po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Amazon buys SpaceX rocket launches for Kuiper ...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/amazon-buys-sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kevin Hart shares his No. 1 'secret weapon' fo...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/kevin-hart-say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Money market funds may deliver a surprise tax ...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/money-market-f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Saudi Arabia is struggling to boost oil prices...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/saudi-arabia-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Goldman says buy beer powerhouse Constellation...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/goldman-says-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Here's why we're not worried about Starbucks s...</td>\n",
       "      <td>December 1, 2023</td>\n",
       "      <td>https://www.cnbc.com/2023/12/01/heres-why-were...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 News              Time  \\\n",
       "0   Why a strong Black Friday may not mean a blowo...        27 Min Ago   \n",
       "1   IMF chief makes the case for carbon pricing at...       5 Hours Ago   \n",
       "2   In Congress and in class: Rep. Don Beyer works...      17 Hours Ago   \n",
       "3   Case for gold fever: NewEdge Wealth sees recor...      21 Hours Ago   \n",
       "4   Signs of a sector rotation — plus 2 more theme...      22 Hours Ago   \n",
       "5   Disney's 'Wish' director left med school for a...      22 Hours Ago   \n",
       "6   We spent $4.5 million to turn this abandoned s...      22 Hours Ago   \n",
       "7   Worth the money: 4 items that will upgrade you...      22 Hours Ago   \n",
       "8   I spent 20 years studying foods 100-year-old p...      23 Hours Ago   \n",
       "9   Trailer park caretaker surprises his hometown ...      23 Hours Ago   \n",
       "10  Beyoncé film: Criticism motivated 11-year-old ...      23 Hours Ago   \n",
       "11  Investors mourn the loss of one-of-a-kind lege...      23 Hours Ago   \n",
       "12  How some of 2023's biggest AI winners have far...      23 Hours Ago   \n",
       "13  Analysts top picks for December's include this...      23 Hours Ago   \n",
       "14  Here’s what the S&P 500’s summer hot streak ca...      24 Hours Ago   \n",
       "15  How $100 billion mining giant Rio Tinto is poi...      24 Hours Ago   \n",
       "16  Social Security benefits are reduced for publi...      24 Hours Ago   \n",
       "17  Pfizer's twice-daily weight loss pill joins a ...  December 2, 2023   \n",
       "18  Exxon Mobil CEO urges COP28 climate summit to ...  December 2, 2023   \n",
       "19  Cramer's optimistic on retail stocks and consu...  December 1, 2023   \n",
       "20  Cramer's Lightning Round: ImmunityBio is 'a ve...  December 1, 2023   \n",
       "21  Cramer's week ahead: Pay attention to Friday's...  December 1, 2023   \n",
       "22  Amazon broke federal labor law in calling Stat...  December 1, 2023   \n",
       "23            Uber shares pop on inclusion in S&P 500  December 1, 2023   \n",
       "24  Amazon buys SpaceX rocket launches for Kuiper ...  December 1, 2023   \n",
       "25  Kevin Hart shares his No. 1 'secret weapon' fo...  December 1, 2023   \n",
       "26  Money market funds may deliver a surprise tax ...  December 1, 2023   \n",
       "27  Saudi Arabia is struggling to boost oil prices...  December 1, 2023   \n",
       "28  Goldman says buy beer powerhouse Constellation...  December 1, 2023   \n",
       "29  Here's why we're not worried about Starbucks s...  December 1, 2023   \n",
       "\n",
       "                                           News links  \n",
       "0   https://www.cnbc.com/2023/12/03/what-strong-bl...  \n",
       "1   https://www.cnbc.com/2023/12/03/imf-chief-make...  \n",
       "2   https://www.cnbc.com/2023/12/02/in-congress-an...  \n",
       "3   https://www.cnbc.com/2023/12/02/case-for-gold-...  \n",
       "4   https://www.cnbc.com/2023/12/02/signs-of-a-sec...  \n",
       "5   https://www.cnbc.com/2023/12/02/disneys-wish-d...  \n",
       "6   https://www.cnbc.com/2023/12/02/schwab-pennsyl...  \n",
       "7   https://www.cnbc.com/2023/12/02/items-to-upgra...  \n",
       "8   https://www.cnbc.com/2023/12/02/i-spent-20-yea...  \n",
       "9   https://www.cnbc.com/2023/12/02/trailer-park-c...  \n",
       "10  https://www.cnbc.com/2023/12/02/beyonce-film-h...  \n",
       "11  https://www.cnbc.com/2023/12/02/charlie-munger...  \n",
       "12  https://www.cnbc.com/2023/12/02/how-these-ai-w...  \n",
       "13  https://www.cnbc.com/2023/12/02/decembers-best...  \n",
       "14  https://www.cnbc.com/2023/12/02/heres-what-the...  \n",
       "15  https://www.cnbc.com/2023/12/02/how-rio-tinto-...  \n",
       "16  https://www.cnbc.com/2023/12/02/social-securit...  \n",
       "17  https://www.cnbc.com/2023/12/02/pfizer-weight-...  \n",
       "18  https://www.cnbc.com/2023/12/02/exxon-mobil-ce...  \n",
       "19  https://www.cnbc.com/2023/12/01/cramers-optimi...  \n",
       "20  https://www.cnbc.com/2023/12/01/cramers-lightn...  \n",
       "21  https://www.cnbc.com/2023/12/01/cramers-week-a...  \n",
       "22  https://www.cnbc.com/2023/12/01/amazon-broke-f...  \n",
       "23  https://www.cnbc.com/2023/12/01/uber-shares-po...  \n",
       "24  https://www.cnbc.com/2023/12/01/amazon-buys-sp...  \n",
       "25  https://www.cnbc.com/2023/12/01/kevin-hart-say...  \n",
       "26  https://www.cnbc.com/2023/12/01/money-market-f...  \n",
       "27  https://www.cnbc.com/2023/12/01/saudi-arabia-i...  \n",
       "28  https://www.cnbc.com/2023/12/01/goldman-says-b...  \n",
       "29  https://www.cnbc.com/2023/12/01/heres-why-were...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''5)Write a python program to scrape mentioned news details from https://www.cnbc.com/world/?region=world and\n",
    "make data frame\n",
    "i) Headline\n",
    "ii) Time\n",
    "iii) News Link'''\n",
    "\n",
    "page09 = requests.get('https://www.cnbc.com/world/?region=world')\n",
    "page09\n",
    "soup12 = BeautifulSoup(page09.content, 'html.parser')\n",
    "links = []\n",
    "\n",
    "for li in soup12.find_all('li', class_='LatestNews-item'):\n",
    "    for a in li.find_all('a', class_='LatestNews-headline'):\n",
    "        links.append(a['href'])\n",
    "len(links)\n",
    "\n",
    "times = []\n",
    "\n",
    "for li in soup12.find_all('li', class_='LatestNews-item'):\n",
    "    for time in li.find_all('time', class_='LatestNews-timestamp'):\n",
    "        times.append(time.text)\n",
    "len(times)\n",
    "\n",
    "headlines = []\n",
    "\n",
    "for li in soup12.find_all('li', class_='LatestNews-item'):\n",
    "    for a in li.find_all('a', class_='LatestNews-headline'):\n",
    "        headlines.append(a.text)\n",
    "headlines\n",
    "\n",
    "\n",
    "data1001 = pd.DataFrame({ 'News' : headlines, 'Time' :times, 'News links': links})\n",
    "data1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57389b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper Title</th>\n",
       "      <th>team</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Paper URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reward is enough</td>\n",
       "      <td>David Silver, Satinder Singh, Doina Precup, Ri...</td>\n",
       "      <td>October 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation in artificial intelligence: Insigh...</td>\n",
       "      <td>Tim Miller</td>\n",
       "      <td>February 2019</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Creativity and artificial intelligence</td>\n",
       "      <td>Margaret A. Boden</td>\n",
       "      <td>August 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conflict-based search for optimal multi-agent ...</td>\n",
       "      <td>Guni Sharon, Roni Stern, Ariel Felner, Nathan ...</td>\n",
       "      <td>February 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Knowledge graphs as tools for explainable mach...</td>\n",
       "      <td>Ilaria Tiddi, Stefan Schlobach</td>\n",
       "      <td>January 2022</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Law and logic: A review from an argumentation ...</td>\n",
       "      <td>Henry Prakken, Giovanni Sartor</td>\n",
       "      <td>October 2015</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Between MDPs and semi-MDPs: A framework for te...</td>\n",
       "      <td>Richard S. Sutton, Doina Precup, Satinder Singh</td>\n",
       "      <td>August 1999</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Explaining individual predictions when feature...</td>\n",
       "      <td>Kjersti Aas, Martin Jullum, Anders Løland</td>\n",
       "      <td>September 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Multiple object tracking: A literature review</td>\n",
       "      <td>Wenhan Luo, Junliang Xing and 4 more</td>\n",
       "      <td>April 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A survey of inverse reinforcement learning: Ch...</td>\n",
       "      <td>Saurabh Arora, Prashant Doshi</td>\n",
       "      <td>August 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Evaluating XAI: A comparison of rule-based and...</td>\n",
       "      <td>Jasper van der Waa, Elisabeth Nieuwburg, Anita...</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Explainable AI tools for legal reasoning about...</td>\n",
       "      <td>Joe Collenette, Katie Atkinson, Trevor Bench-C...</td>\n",
       "      <td>April 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hard choices in artificial intelligence</td>\n",
       "      <td>Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz</td>\n",
       "      <td>November 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Assessing the communication gap between AI mod...</td>\n",
       "      <td>Oskar Wysocki, Jessica Katharine Davies and 5 ...</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Explaining black-box classifiers using post-ho...</td>\n",
       "      <td>Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...</td>\n",
       "      <td>May 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The Hanabi challenge: A new frontier for AI re...</td>\n",
       "      <td>Nolan Bard, Jakob N. Foerster and 13 more</td>\n",
       "      <td>March 2020</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wrappers for feature subset selection</td>\n",
       "      <td>Ron Kohavi, George H. John</td>\n",
       "      <td>December 1997</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Artificial cognition for social human–robot in...</td>\n",
       "      <td>Séverin Lemaignan, Mathieu Warnier and 3 more</td>\n",
       "      <td>June 2017</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>A review of possible effects of cognitive bias...</td>\n",
       "      <td>Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz</td>\n",
       "      <td>June 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The multifaceted impact of Ada Lovelace in the...</td>\n",
       "      <td>Luigia Carlucci Aiello</td>\n",
       "      <td>June 2016</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Robot ethics: Mapping the issues for a mechani...</td>\n",
       "      <td>Patrick Lin, Keith Abney, George Bekey</td>\n",
       "      <td>April 2011</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Reward (Mis)design for autonomous driving</td>\n",
       "      <td>W. Bradley Knox, Alessandro Allievi and 3 more</td>\n",
       "      <td>March 2023</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Planning and acting in partially observable st...</td>\n",
       "      <td>Leslie Pack Kaelbling, Michael L. Littman, Ant...</td>\n",
       "      <td>May 1998</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>What do we want from Explainable Artificial In...</td>\n",
       "      <td>Markus Langer, Daniel Oster and 6 more</td>\n",
       "      <td>July 2021</td>\n",
       "      <td>https://www.sciencedirect.com/science/article/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paper Title  \\\n",
       "0                                    Reward is enough   \n",
       "1   Explanation in artificial intelligence: Insigh...   \n",
       "2              Creativity and artificial intelligence   \n",
       "3   Conflict-based search for optimal multi-agent ...   \n",
       "4   Knowledge graphs as tools for explainable mach...   \n",
       "5   Law and logic: A review from an argumentation ...   \n",
       "6   Between MDPs and semi-MDPs: A framework for te...   \n",
       "7   Explaining individual predictions when feature...   \n",
       "8       Multiple object tracking: A literature review   \n",
       "9   A survey of inverse reinforcement learning: Ch...   \n",
       "10  Evaluating XAI: A comparison of rule-based and...   \n",
       "11  Explainable AI tools for legal reasoning about...   \n",
       "12            Hard choices in artificial intelligence   \n",
       "13  Assessing the communication gap between AI mod...   \n",
       "14  Explaining black-box classifiers using post-ho...   \n",
       "15  The Hanabi challenge: A new frontier for AI re...   \n",
       "16              Wrappers for feature subset selection   \n",
       "17  Artificial cognition for social human–robot in...   \n",
       "18  A review of possible effects of cognitive bias...   \n",
       "19  The multifaceted impact of Ada Lovelace in the...   \n",
       "20  Robot ethics: Mapping the issues for a mechani...   \n",
       "21          Reward (Mis)design for autonomous driving   \n",
       "22  Planning and acting in partially observable st...   \n",
       "23  What do we want from Explainable Artificial In...   \n",
       "\n",
       "                                                 team  Published Date  \\\n",
       "0   David Silver, Satinder Singh, Doina Precup, Ri...    October 2021   \n",
       "1                                          Tim Miller   February 2019   \n",
       "2                                   Margaret A. Boden     August 1998   \n",
       "3   Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   February 2015   \n",
       "4                      Ilaria Tiddi, Stefan Schlobach    January 2022   \n",
       "5                      Henry Prakken, Giovanni Sartor    October 2015   \n",
       "6     Richard S. Sutton, Doina Precup, Satinder Singh     August 1999   \n",
       "7           Kjersti Aas, Martin Jullum, Anders Løland  September 2021   \n",
       "8                Wenhan Luo, Junliang Xing and 4 more      April 2021   \n",
       "9                       Saurabh Arora, Prashant Doshi     August 2021   \n",
       "10  Jasper van der Waa, Elisabeth Nieuwburg, Anita...   February 2021   \n",
       "11  Joe Collenette, Katie Atkinson, Trevor Bench-C...      April 2023   \n",
       "12   Roel Dobbe, Thomas Krendl Gilbert, Yonatan Mintz   November 2021   \n",
       "13  Oskar Wysocki, Jessica Katharine Davies and 5 ...      March 2023   \n",
       "14  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...        May 2021   \n",
       "15          Nolan Bard, Jakob N. Foerster and 13 more      March 2020   \n",
       "16                         Ron Kohavi, George H. John   December 1997   \n",
       "17      Séverin Lemaignan, Mathieu Warnier and 3 more       June 2017   \n",
       "18    Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz       June 2021   \n",
       "19                             Luigia Carlucci Aiello       June 2016   \n",
       "20             Patrick Lin, Keith Abney, George Bekey      April 2011   \n",
       "21     W. Bradley Knox, Alessandro Allievi and 3 more      March 2023   \n",
       "22  Leslie Pack Kaelbling, Michael L. Littman, Ant...        May 1998   \n",
       "23             Markus Langer, Daniel Oster and 6 more       July 2021   \n",
       "\n",
       "                                            Paper URL  \n",
       "0   https://www.sciencedirect.com/science/article/...  \n",
       "1   https://www.sciencedirect.com/science/article/...  \n",
       "2   https://www.sciencedirect.com/science/article/...  \n",
       "3   https://www.sciencedirect.com/science/article/...  \n",
       "4   https://www.sciencedirect.com/science/article/...  \n",
       "5   https://www.sciencedirect.com/science/article/...  \n",
       "6   https://www.sciencedirect.com/science/article/...  \n",
       "7   https://www.sciencedirect.com/science/article/...  \n",
       "8   https://www.sciencedirect.com/science/article/...  \n",
       "9   https://www.sciencedirect.com/science/article/...  \n",
       "10  https://www.sciencedirect.com/science/article/...  \n",
       "11  https://www.sciencedirect.com/science/article/...  \n",
       "12  https://www.sciencedirect.com/science/article/...  \n",
       "13  https://www.sciencedirect.com/science/article/...  \n",
       "14  https://www.sciencedirect.com/science/article/...  \n",
       "15  https://www.sciencedirect.com/science/article/...  \n",
       "16  https://www.sciencedirect.com/science/article/...  \n",
       "17  https://www.sciencedirect.com/science/article/...  \n",
       "18  https://www.sciencedirect.com/science/article/...  \n",
       "19  https://www.sciencedirect.com/science/article/...  \n",
       "20  https://www.sciencedirect.com/science/article/...  \n",
       "21  https://www.sciencedirect.com/science/article/...  \n",
       "22  https://www.sciencedirect.com/science/article/...  \n",
       "23  https://www.sciencedirect.com/science/article/...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''6) Write a python program to scrape the details of most downloaded articles from AI in last 90\n",
    "days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles\n",
    "Scrape below mentioned details and make data frame'''\n",
    "\n",
    "\n",
    "page8 = requests.get('https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles')\n",
    "page8\n",
    "\n",
    "soup9 = BeautifulSoup(page8.content, 'html.parser')\n",
    "\n",
    "headlines99 = [h.text.strip() for h in soup9.select('.sc-1qrq3sd-1.gRGSUS')]\n",
    "headlines99\n",
    "\n",
    "authors= []\n",
    "for i in soup9.find_all('span' , class_ =\"sc-1w3fpd7-0 dnCnAO\"):\n",
    "    authors.append(i.text.strip())\n",
    "authors\n",
    "\n",
    "date= []\n",
    "for i in soup9.find_all('span' , class_ =\"sc-1thf9ly-2 dvggWt\"):\n",
    "    date.append(i.text.strip())\n",
    "date\n",
    "\n",
    "article_links = []\n",
    "for a in soup9.find_all('a', class_='sc-5smygv-0 fIXTHm', href=True):\n",
    "    article_links.append(a['href'])\n",
    "article_links\n",
    "\n",
    "\n",
    "data09 = pd.DataFrame({'Paper Title' : headlines99, 'team' : authors, 'Published Date' :date, 'Paper URL' : article_links})\n",
    "data09\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d70ecd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restaurent</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>loaction</th>\n",
       "      <th>rating</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>₹ 2,000 for 2 (approx) | Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>₹ 3,000 for 2 (approx) | Italian, Continental</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>₹ 2,400 for 2 (approx) | North Indian, Italian</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>₹ 1,700 for 2 (approx) | North Indian, Chinese</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>₹ 1,800 for 2 (approx) | North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>₹ 1,900 for 2 (approx) | North Indian</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Barbeque TimesM2K Corporate Park,Sector 51...</td>\n",
       "      <td>₹ 1,500 for 2 (approx) | North Indian, Contine...</td>\n",
       "      <td>M2K Corporate Park,Sector 51, Gurgaon</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          restaurent  \\\n",
       "0      Castle BarbequeConnaught Place, Central Delhi   \n",
       "1  Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "2    India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "3  The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "4  Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "5  The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "6  The Barbeque TimesM2K Corporate Park,Sector 51...   \n",
       "\n",
       "                                             cuisine  \\\n",
       "0     ₹ 2,000 for 2 (approx) | Chinese, North Indian   \n",
       "1      ₹ 3,000 for 2 (approx) | Italian, Continental   \n",
       "2     ₹ 2,400 for 2 (approx) | North Indian, Italian   \n",
       "3     ₹ 1,700 for 2 (approx) | North Indian, Chinese   \n",
       "4              ₹ 1,800 for 2 (approx) | North Indian   \n",
       "5              ₹ 1,900 for 2 (approx) | North Indian   \n",
       "6  ₹ 1,500 for 2 (approx) | North Indian, Contine...   \n",
       "\n",
       "                                            loaction rating  \\\n",
       "0                     Connaught Place, Central Delhi      4   \n",
       "1  The Leela Ambience Convention Hotel,Shahdara, ...    4.3   \n",
       "2               Hilton Garden Inn,Saket, South Delhi    3.9   \n",
       "3                 Gardens Galleria,Sector 38A, Noida    3.9   \n",
       "4     Taurus Sarovar Portico,Mahipalpur, South Delhi    3.7   \n",
       "5  Indirapuram Habitat Centre,Indirapuram, Ghaziabad    3.8   \n",
       "6              M2K Corporate Park,Sector 51, Gurgaon    4.1   \n",
       "\n",
       "                                           image_url  \n",
       "0  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' 7) Write a python program to scrape mentioned details from dineout.co.inand make data frame\n",
    "i) Restaurant name\n",
    "ii) Cuisine\n",
    "iii) Location\n",
    "iv) Ratings\n",
    "v) Image URL'''\n",
    "\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "page \n",
    "\n",
    "soup = BeautifulSoup(page.content)\n",
    "soup\n",
    "\n",
    "hotel = []\n",
    "for name in soup.find_all('div', class_ = \"restnt-info cursor\" ):\n",
    "    hotel.append(name.text)\n",
    "hotel\n",
    "\n",
    "place = []\n",
    "for loca in soup.find_all('div', class_ = \"restnt-loc ellipsis\"  ):\n",
    "    place.append(loca.text) \n",
    "place\n",
    "\n",
    "cost = []\n",
    "for price in soup.find_all('div', class_ = \"detail-info\"  ):\n",
    "    cost.append(price.text)\n",
    "cost\n",
    "\n",
    "image_url = []\n",
    "for i in soup.find_all('img', class_ = 'no-img'):\n",
    "    image_url.append(i['data-src'])\n",
    "image_url\n",
    "\n",
    "ratings = []\n",
    "for i in soup.find_all('div', class_=\"restnt-rating rating-4\"):\n",
    "    ratings.append(i.text)\n",
    "ratings\n",
    "\n",
    "df = pd.DataFrame({'restaurent' :hotel,'cuisine' : cost, 'loaction': place , 'rating': ratings , 'image_url': image_url } )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e864cefa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d7037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d998b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e6347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d108fc94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb65229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17807a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660cd367",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e55516",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179d0eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4449f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708570db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57557b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
